{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5BV3l8YpOS3B"
   },
   "outputs": [],
   "source": [
    "EPOCH = 6\n",
    "BATCH_SIZE = 20\n",
    "LEARNING_RATE = 1e-3\n",
    "THRESHOLD = 0.5\n",
    "DROPOUT_RATE = 0.1\n",
    "\n",
    "CONTEXT_MAX_LEN = 300\n",
    "RESPONSE_MAX_LEN = 30\n",
    "\n",
    "LOGISTICLOSS = True\n",
    "BUILD_NEW_DICT = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jr7y9GLOtQ7h"
   },
   "source": [
    "# Import package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "iKlCcRadtG6O",
    "outputId": "bba483a7-5bf1-4eb4-b0f1-55de62f79875"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "from tqdm import trange\n",
    "from itertools import repeat\n",
    "from multiprocessing import Pool\n",
    "from nltk.tokenize import word_tokenize\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('train.json') as f:\n",
    "    train_raw = json.load(f)\n",
    "    \n",
    "with open('test.json') as f:\n",
    "    test_raw = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data-split': 'train',\n",
      " 'example-id': 1000001,\n",
      " 'messages-so-far': [{'speaker': 'participant_1',\n",
      "                      'utterance': 'Hi, I want to run a graphical application '\n",
      "                                   'from the command line, here is the script '\n",
      "                                   'I wrote: https://paste8.com/4XQiHrXZ - '\n",
      "                                   \"it's Ubuntu Server 12.04 + Unity. What I \"\n",
      "                                   'get is an error from xhost \"unable to open '\n",
      "                                   'display :0\" and from the graphical '\n",
      "                                   'application I want to use (Sikuli) \"Can\\'t '\n",
      "                                   \"connect to X11 window server using ':0' as \"\n",
      "                                   'the value of the DISPLAY variable.\". I\\'ve '\n",
      "                                   'tried using DISPLAY:=1 as I use this '\n",
      "                                   'number when connecting with a VNC client '\n",
      "                                   \"but it doesn't wo. rk either...\"},\n",
      "                     {'speaker': 'participant_2', 'utterance': 'is X running?'},\n",
      "                     {'speaker': 'participant_1',\n",
      "                      'utterance': 'I think so: https://paste8.com/HvhlT6vO.  '\n",
      "                                   'maybe you prefer this check: '\n",
      "                                   'https://paste8.com/0OhcBmfB'},\n",
      "                     {'speaker': 'participant_2',\n",
      "                      'utterance': 'these days you use lightdm (or gdm, kdm) '\n",
      "                                   \"to start X, so i'd try to kill what's \"\n",
      "                                   'there but unreachable with \"sudo killall '\n",
      "                                   'X\" and then \"sudo service lightdm start\"'},\n",
      "                     {'speaker': 'participant_1',\n",
      "                      'utterance': 'what do I kill precisely? because it says '\n",
      "                                   '\"X: no such process\"'},\n",
      "                     {'speaker': 'participant_2',\n",
      "                      'utterance': \"nothing, X wasn't running if you get that, \"\n",
      "                                   'proceed with \"sudo service lightdm start\" '\n",
      "                                   'and then test your script'},\n",
      "                     {'speaker': 'participant_1',\n",
      "                      'utterance': 'alright but \"start: Job is already '\n",
      "                                   'running: lightdm\"'},\n",
      "                     {'speaker': 'participant_2',\n",
      "                      'utterance': 'worm: try restart'},\n",
      "                     {'speaker': 'participant_1',\n",
      "                      'utterance': 'I did but I get \"No protocol specified. \" '\n",
      "                                   'followed by \"xhost: unable to open display '\n",
      "                                   ':0\" when executing my script (i.e. '\n",
      "                                   'https://paste8.com/4XQiHrXZ). does it '\n",
      "                                   'matter I run everything from a root tty? '\n",
      "                                   \"because that's what I do\"},\n",
      "                     {'speaker': 'participant_2',\n",
      "                      'utterance': 'ahh, not a good idea to try to start X as '\n",
      "                                   'root no.  now your regular users '\n",
      "                                   '~/.Xauthority file is probably owned by '\n",
      "                                   'root, check that.  what does \"ls -la '\n",
      "                                   '~/.Xauthority\" give you?'},\n",
      "                     {'speaker': 'participant_1',\n",
      "                      'utterance': 'yes I got /root/.Xauthority I need to '\n",
      "                                   'append an entry for my regular user '\n",
      "                                   'right?'},\n",
      "                     {'speaker': 'participant_2',\n",
      "                      'utterance': 'check if your regular user still owns his '\n",
      "                                   '.Xauthority file and remove the one for '\n",
      "                                   'root'},\n",
      "                     {'speaker': 'participant_1',\n",
      "                      'utterance': 'there is no .Xauthority for my regular '\n",
      "                                   \"user I'm afraid\"},\n",
      "                     {'speaker': 'participant_2',\n",
      "                      'utterance': 'well, copy the one from root to the user '\n",
      "                                   '/home and make him own it, use the chown '\n",
      "                                   'command.  sudo chown $USER:$USER '\n",
      "                                   '$HOME/.Xauthority'},\n",
      "                     {'speaker': 'participant_1',\n",
      "                      'utterance': 'done, but running $sudo service lightdm '\n",
      "                                   'start; returns \"Sorry, user <myuser> is '\n",
      "                                   \"not allowed to execute '/usr/sbin/service \"\n",
      "                                   'lightdm start\\' as root on <myhost>.\"'},\n",
      "                     {'speaker': 'participant_2',\n",
      "                      'utterance': 'is the regular user in the sudoers?'},\n",
      "                     {'speaker': 'participant_1',\n",
      "                      'utterance': 'no, I believe I have to create a file in '\n",
      "                                   \"/etc/sudoers.d but I don't know the syntax \"\n",
      "                                   'yet'}],\n",
      " 'options-for-correct-answers': [{'candidate-id': '0R1OTUTWT416',\n",
      "                                  'utterance': 'are you still running in root '\n",
      "                                               'terminal? if so, try from a '\n",
      "                                               \"non-root one.. i've got to go \"\n",
      "                                               \"prepare dinner so i'll be afk \"\n",
      "                                               '.. ask the channel for help on '\n",
      "                                               'that, hope you get things up'}],\n",
      " 'options-for-next': [{'candidate-id': 'GLMRY50D3OMQ', 'utterance': 'quite'},\n",
      "                      {'candidate-id': '06Q4I0WB5F7D',\n",
      "                       'utterance': 'hey join #.  so i can tell you things '\n",
      "                                    \"that the kiddies won't latch on to\"},\n",
      "                      {'candidate-id': 'QGOHDF0UT464',\n",
      "                       'utterance': 'did you complete the ubuntu '\n",
      "                                    'installation??'},\n",
      "                      {'candidate-id': 'O1JHGMRV7POK',\n",
      "                       'utterance': 'how did you run mplayer?'},\n",
      "                      {'candidate-id': '8A3DLZ1C2YPM',\n",
      "                       'utterance': 'a skype replacement? i think google talk '\n",
      "                                    \"works in the US (i wouldn't know i'm in \"\n",
      "                                    'uk)'},\n",
      "                      {'candidate-id': '4CMEGXSS1Z5J',\n",
      "                       'utterance': 'you only need the libraries for each.... '\n",
      "                                    \"... which isn't too expensive\"},\n",
      "                      {'candidate-id': 'OVEJI3BHWK34',\n",
      "                       'utterance': 'try sudo apt-get install ubuntu-desktop'},\n",
      "                      {'candidate-id': 'LWHUA5X5Y66E',\n",
      "                       'utterance': \"which error is that?. btw don't make us \"\n",
      "                                    'ask these questions'},\n",
      "                      {'candidate-id': 'V551PDECQCHG',\n",
      "                       'utterance': \"I'm not sure there is one, you may need \"\n",
      "                                    'to just tweak ~/.config/xfce4.'},\n",
      "                      {'candidate-id': 'NP41K6AOICPR',\n",
      "                       'utterance': \"- you'll figure it out - best to you.\"},\n",
      "                      {'candidate-id': '8L0VHAG4UUKQ',\n",
      "                       'utterance': 'try running \"sudo updatedb\" then \"locate '\n",
      "                                    'eclipse\". youll find it then'},\n",
      "                      {'candidate-id': '41GKOPQBUHU6',\n",
      "                       'utterance': \"I don't remember though. anyone else? how \"\n",
      "                                    'to get verbose output during a boot? turn '\n",
      "                                    'of boot splash during live cd?'},\n",
      "                      {'candidate-id': 'OK9ELYL65VR7',\n",
      "                       'utterance': \"It's painful that's true :p.\"},\n",
      "                      {'candidate-id': '88U6MVJDS9XE',\n",
      "                       'utterance': 'Try cat /etc/issue.  Sorry, '\n",
      "                                    'debian_version is for the debian version, '\n",
      "                                    'not the ubuntu version'},\n",
      "                      {'candidate-id': '6RQ2F0O080BC',\n",
      "                       'utterance': '1 mini pastbin'},\n",
      "                      {'candidate-id': 'H2BJMGZRGOIM',\n",
      "                       'utterance': 'Hey man, earcandy killed my audio '\n",
      "                                    'completely'},\n",
      "                      {'candidate-id': 'J0T04P7GFYDA',\n",
      "                       'utterance': 'pdfinfo file.pdf , the last line is the '\n",
      "                                    'pdf version'},\n",
      "                      {'candidate-id': 'AM1WCAV9LXHC',\n",
      "                       'utterance': 'when you install the theme, you have to '\n",
      "                                    'select it in gnome-appearance properties. '\n",
      "                                    'The theme may not show up as a complete '\n",
      "                                    'theme, so then you would have to click '\n",
      "                                    '\"Customize\", and find the theme in the '\n",
      "                                    '\"Controls\" tab'},\n",
      "                      {'candidate-id': '2949SYU4K5ZQ',\n",
      "                       'utterance': 'do you really want it to \"integrate\" with '\n",
      "                                    'firefox?'},\n",
      "                      {'candidate-id': 'YXQ9S7A16DOL',\n",
      "                       'utterance': 'you can use rcconf to enable plymouth >> '\n",
      "                                    'sudo apt-gt install rcconf , then sudo '\n",
      "                                    'rcconf.  you can also do sudo serivce '\n",
      "                                    'plymouth start. service*'},\n",
      "                      {'candidate-id': 'KJ4S8CECCD4A',\n",
      "                       'utterance': 'all over... but mostly in /usr/bin'},\n",
      "                      {'candidate-id': '6SLYYYRCNRXJ',\n",
      "                       'utterance': 'if you spread the swap out over several '\n",
      "                                    'drives its suppose to be more '\n",
      "                                    'efficient/faster. i hear.'},\n",
      "                      {'candidate-id': '8R5RCFTAM2ZG',\n",
      "                       'utterance': 'if you want gnome 2.14: go with dapper - '\n",
      "                                    \"it's mature and stable enough for \"\n",
      "                                    'everyday use'},\n",
      "                      {'candidate-id': 'KB7J3DMD2ZM4',\n",
      "                       'utterance': 'either way :)'},\n",
      "                      {'candidate-id': 'UYQ8DC3FP5RE',\n",
      "                       'utterance': '-> you can try i guess...and til us how '\n",
      "                                    'it goes'},\n",
      "                      {'candidate-id': '1BRKQIXN02IS',\n",
      "                       'utterance': 'sorry, that is offtopic here.'},\n",
      "                      {'candidate-id': '2XP3ZQBWGKKY',\n",
      "                       'utterance': 'gtkhtml - What do you show as the latest. '\n",
      "                                    '?'},\n",
      "                      {'candidate-id': '5IA5N1QZWITA',\n",
      "                       'utterance': 'there are : 802.11b/g/n - 802.11b/g - '\n",
      "                                    '802.11g - 802.11b'},\n",
      "                      {'candidate-id': 'TMXEVZ3VB0AV',\n",
      "                       'utterance': '#opensuse #freenode google, opensuse.com'},\n",
      "                      {'candidate-id': 'V16LN56CWFTO',\n",
      "                       'utterance': 'look in fdisk if partition types are raid '\n",
      "                                    'auto detect...'},\n",
      "                      {'candidate-id': 'PFVJKS0VZLIG',\n",
      "                       'utterance': \"can't help you there sean as I don't use \"\n",
      "                                    \"Unity. I don't think so\"},\n",
      "                      {'candidate-id': '4TKVDEHSXQE7',\n",
      "                       'utterance': 'did you add a second line in fstab using '\n",
      "                                    'cdrom0'},\n",
      "                      {'candidate-id': 'U1NDUO2BSXAK',\n",
      "                       'utterance': 'sudo aptitude install transmission'},\n",
      "                      {'candidate-id': '8IRPPC91FKBL',\n",
      "                       'utterance': \"oh I get it now, it's just like minicom.  \"\n",
      "                                    'pastebin the help.  like irecovery -s , '\n",
      "                                    'and then help.  also try \"(whatever_cmds) '\n",
      "                                    '| irecovery -s\"'},\n",
      "                      {'candidate-id': '0R1OTUTWT416',\n",
      "                       'utterance': 'are you still running in root terminal? '\n",
      "                                    \"if so, try from a non-root one.. i've got \"\n",
      "                                    \"to go prepare dinner so i'll be afk .. \"\n",
      "                                    'ask the channel for help on that, hope '\n",
      "                                    'you get things up'},\n",
      "                      {'candidate-id': 'H5JCB1MGYOVL',\n",
      "                       'utterance': 'No I have them but when I try to apply '\n",
      "                                    'other ones it says it does wit but it '\n",
      "                                    \"really doesn't...  When I try to change \"\n",
      "                                    'the resolution with the Nvidia control '\n",
      "                                    'panel I get this error: Failed to set '\n",
      "                                    \"MetaMode (4) 'CRT-0: 1680x1050 @1680x1050 \"\n",
      "                                    \"+0+0' (Mode 1680x1050, id: 53) on X \"\n",
      "                                    'screen 0. Would you like to remove this '\n",
      "                                    'MetaMode?'},\n",
      "                      {'candidate-id': 'O90UWPVHR1E4',\n",
      "                       'utterance': 'I did, and now I use SuSe heh'},\n",
      "                      {'candidate-id': 'DO5KB93BW7PC',\n",
      "                       'utterance': 'i dont know, but ti hurts when package '\n",
      "                                    'managers break. try synaptic'},\n",
      "                      {'candidate-id': '74S8AKW8ZWFU',\n",
      "                       'utterance': 'Not sure how to do config files, but I '\n",
      "                                    'know if you open synaptic you can save a '\n",
      "                                    'package configuration and load that onto '\n",
      "                                    'another system.  Best thing you could do '\n",
      "                                    'is if you have any local config files '\n",
      "                                    'back them up with your home folder, any '\n",
      "                                    'global ones you will have to do manually'},\n",
      "                      {'candidate-id': 'BDPHDNFS14TR',\n",
      "                       'utterance': 'Since you apparently use irssi, perhaps '\n",
      "                                    'you have seen this issue... sometimes all '\n",
      "                                    'of the text disappears except the active '\n",
      "                                    'line. The only way I know of to get it '\n",
      "                                    'back to normal is to detach the screen, '\n",
      "                                    'reset the console and then reattach to '\n",
      "                                    'the screen. Maybe you know of something '\n",
      "                                    'that will keep this from happening...'},\n",
      "                      {'candidate-id': '6ZU1WCPRH7HU', 'utterance': 'xrandr'},\n",
      "                      {'candidate-id': 'U3XLAOCW6IF5',\n",
      "                       'utterance': 'gimme a sec then :)'},\n",
      "                      {'candidate-id': 'UA7XT4WAV0HT',\n",
      "                       'utterance': \"that's interesting. I use kde which uses \"\n",
      "                                    \"a different sound server, though, so I'm \"\n",
      "                                    'not clear on exactly what is going on '\n",
      "                                    'there.'},\n",
      "                      {'candidate-id': 'FBBJP0RX862J',\n",
      "                       'utterance': 'not sure .... im using bubble style'},\n",
      "                      {'candidate-id': '4ROLOBX3R8KY',\n",
      "                       'utterance': 'lshw -C Network'},\n",
      "                      {'candidate-id': 'OWQW6GWHXT61',\n",
      "                       'utterance': 'using a package manager yes'},\n",
      "                      {'candidate-id': 'GRWGOQ7ISY7Q',\n",
      "                       'utterance': 'firefox or inkscape'},\n",
      "                      {'candidate-id': '7CLHNAJYWL79',\n",
      "                       'utterance': 'wrong channel'},\n",
      "                      {'candidate-id': '9P3VPPDO62T1',\n",
      "                       'utterance': 'i think your looking for 0644 not 0755'},\n",
      "                      {'candidate-id': '2FOGKCC0R6S7',\n",
      "                       'utterance': 'there is a subtitle check box.  there is '\n",
      "                                    'also the #handbrake channel'},\n",
      "                      {'candidate-id': 'UZEMKNS5PTHD',\n",
      "                       'utterance': '\"Deleted on 2012-16-20: (From Debian) '\n",
      "                                    'ROM; confusion with GNU ddrescue; Debian '\n",
      "                                    'bug #677101\". you probably want '\n",
      "                                    'gddrescue'},\n",
      "                      {'candidate-id': 'LNAVA3IVJS6J',\n",
      "                       'utterance': 'if you have your zone files there and '\n",
      "                                    'bind config as well I think you should be '\n",
      "                                    'fine'},\n",
      "                      {'candidate-id': 'FY9VUEBQF3BV',\n",
      "                       'utterance': 'no idea. i bet you can find something '\n",
      "                                    'though.'},\n",
      "                      {'candidate-id': '8UGCJBUBQDW7',\n",
      "                       'utterance': 'do a lspci'},\n",
      "                      {'candidate-id': 'XKJ28ZUVKSMO', 'utterance': '!ccsm'},\n",
      "                      {'candidate-id': 'UHMOIL4BI2KR',\n",
      "                       'utterance': 'EasyUbuntu is a script that automates '\n",
      "                                    'installation of some items. Use at your '\n",
      "                                    'own risk. See '\n",
      "                                    'http://easyubuntu.freecontrib.org/ ; for '\n",
      "                                    'help and or discussions about EasyUbuntu '\n",
      "                                    'please join #easyubuntu.'},\n",
      "                      {'candidate-id': 'B1IOB83YM72K',\n",
      "                       'utterance': 'FloridayGuy: Oh, never mind. That was a '\n",
      "                                    'bad joke'},\n",
      "                      {'candidate-id': '6U4ASY249IG8',\n",
      "                       'utterance': 'you will need to sudo. check that file to '\n",
      "                                    \"see what it contains first - that's a \"\n",
      "                                    'debian solution'},\n",
      "                      {'candidate-id': 'YF4VKXZFSRDV',\n",
      "                       'utterance': 'Yep, it shuts stuff down, or at least, '\n",
      "                                    'tells them to'},\n",
      "                      {'candidate-id': 'GYEEWQGXX4LG',\n",
      "                       'utterance': 'testdisk will recover your stuff'},\n",
      "                      {'candidate-id': 'F5WD93WLMNVA',\n",
      "                       'utterance': 'They got hacked.'},\n",
      "                      {'candidate-id': 'Z2SS5WEM55KE',\n",
      "                       'utterance': 'you need the qt -dev package, search for '\n",
      "                                    'packages with the following words in '\n",
      "                                    'their name: lib, qt, -dev'},\n",
      "                      {'candidate-id': 'O8DHWD69OIBO',\n",
      "                       'utterance': '2>/dev/null.  sorry > /dev/null'},\n",
      "                      {'candidate-id': 'QBVBCUDLVTHH',\n",
      "                       'utterance': 'artan1s amule, gtk gnutella limewire'},\n",
      "                      {'candidate-id': 'FPYSDOG503NQ',\n",
      "                       'utterance': \"RH folks are working on it, can't use \"\n",
      "                                    'their code to make a .deb?'},\n",
      "                      {'candidate-id': 'W3RH33KZH6JL',\n",
      "                       'utterance': 'it fails for me too :). but nevertheless '\n",
      "                                    'i have X running :)'},\n",
      "                      {'candidate-id': 'ERQEP40Q2J3G',\n",
      "                       'utterance': 'what is the other OS? vista i assume?'},\n",
      "                      {'candidate-id': 'EU6I8FRTXZFX',\n",
      "                       'utterance': '/etc/network/.  there is a bunch of files '\n",
      "                                    'there'},\n",
      "                      {'candidate-id': 'FQTWFXRGJTDH',\n",
      "                       'utterance': 'No not me.'},\n",
      "                      {'candidate-id': 'DYZHV3KYO703',\n",
      "                       'utterance': 'Which one?'},\n",
      "                      {'candidate-id': 'PLBBUTF126N3',\n",
      "                       'utterance': 'install i8kutils'},\n",
      "                      {'candidate-id': 'A9KCEU8THDR6',\n",
      "                       'utterance': 'How can I change which packages are '\n",
      "                                    'installed as part of ubuntu?'},\n",
      "                      {'candidate-id': '2O9YLMGCF24P',\n",
      "                       'utterance': 'O.o how did you install it exactly?'},\n",
      "                      {'candidate-id': 'I7XOQ996AIZY', 'utterance': 'ifconfig'},\n",
      "                      {'candidate-id': '3V10HH38AKRC',\n",
      "                       'utterance': 'Applications > Sound & Video > Sound '\n",
      "                                    'Recorder'},\n",
      "                      {'candidate-id': '52NKI2GF2V6M',\n",
      "                       'utterance': 'just for curiosity: why does one want a '\n",
      "                                    'GUI for something automatically done?'},\n",
      "                      {'candidate-id': 'AHI16A3ATDK2',\n",
      "                       'utterance': 'the server has the speaks. speakers'},\n",
      "                      {'candidate-id': 'ENP18CYSU7FI',\n",
      "                       'utterance': \"Good deal, All's well that ends well.\"},\n",
      "                      {'candidate-id': '1CQVA0KBR081',\n",
      "                       'utterance': 'do you have another interface now ?'},\n",
      "                      {'candidate-id': 'TEF7WC3P0E6M',\n",
      "                       'utterance': \"In that case, I suppose it's possible for \"\n",
      "                                    'a virus to find and infect files on '\n",
      "                                    'different partitions. I could be wrong, '\n",
      "                                    'though. Never had a virus in Linux.'},\n",
      "                      {'candidate-id': 'J2XBGXJFG6LZ',\n",
      "                       'utterance': 'your .gvfs dir'},\n",
      "                      {'candidate-id': 'K07XI5O1ESXX',\n",
      "                       'utterance': \"Uh huh...  That doesn't really answer the \"\n",
      "                                    'question. :)'},\n",
      "                      {'candidate-id': 'ES8ZKE2Z03XD',\n",
      "                       'utterance': 'http://www.livecdlist.com/. 1st link @ '\n",
      "                                    'google..... Also if you spend few minutes '\n",
      "                                    'with google, you will find pretty good '\n",
      "                                    'instructions how to resize a partition '\n",
      "                                    'with live-cd.'},\n",
      "                      {'candidate-id': '27FMA11MJDNA',\n",
      "                       'utterance': \"hickenboot: maybe wine. i'll just check \"\n",
      "                                    'compatibility'},\n",
      "                      {'candidate-id': 'XISJZ00UMKVS',\n",
      "                       'utterance': '~ just purge it then - if things dont '\n",
      "                                    'work out install it again'},\n",
      "                      {'candidate-id': 'SZEJSH5HCJUA',\n",
      "                       'utterance': 'no patience :p'},\n",
      "                      {'candidate-id': 'YEJR0WSJYK8R',\n",
      "                       'utterance': 'how did you install it?'},\n",
      "                      {'candidate-id': '1QBFSA3P43AO',\n",
      "                       'utterance': '<> try installing the latest wine'},\n",
      "                      {'candidate-id': '7490T3TY0SKF',\n",
      "                       'utterance': 'get Nvu from the Ubuntu Universe repo...'},\n",
      "                      {'candidate-id': 'EZHF15SR072J',\n",
      "                       'utterance': 'jpesittpm mptjomg. sorry my dog wont stop '\n",
      "                                    'trying to bite my nose...  this is linux '\n",
      "                                    'not windows.. you have to replace the '\n",
      "                                    'display with meta city.  in terminal type '\n",
      "                                    'in meta city --replace'},\n",
      "                      {'candidate-id': 'UL265QLZ1DZD',\n",
      "                       'utterance': \"that's why I hinted you to look for a \"\n",
      "                                    'button or a menu-item.'},\n",
      "                      {'candidate-id': 'SX8MLZV6RPXN',\n",
      "                       'utterance': '-->#sbackup'},\n",
      "                      {'candidate-id': 'FLBC7LNW2VKC',\n",
      "                       'utterance': 'but it works'},\n",
      "                      {'candidate-id': 'OKS1VJJ1ITEA',\n",
      "                       'utterance': 'right-click in the file display, you '\n",
      "                                    'should get a \"show hidden\" option'},\n",
      "                      {'candidate-id': 'C5EN4XWD0U8Y',\n",
      "                       'utterance': \"that won't solve this problem, though. \"\n",
      "                                    'Give me a minute to read that HOWTO '\n",
      "                                    'thoroughly..  did you actually do the '\n",
      "                                    'Step 1 of the howto?'},\n",
      "                      {'candidate-id': '49SDEPI4LNA1',\n",
      "                       'utterance': 'and the config-options are part of the '\n",
      "                                    'docu'},\n",
      "                      {'candidate-id': '8ZWV2GMDZXHH',\n",
      "                       'utterance': 'mic and speakers on?'},\n",
      "                      {'candidate-id': 'J15I1U5AGPZ7',\n",
      "                       'utterance': \"it's em0, not emo\"},\n",
      "                      {'candidate-id': 'IKJR9V4LS1N4',\n",
      "                       'utterance': 'derander: agreed, though luckily the '\n",
      "                                    'initial install is what, 20 minutes? :P'},\n",
      "                      {'candidate-id': 'KOKJ29MS00S6',\n",
      "                       'utterance': \"Sorry... I've got nothing...\"}],\n",
      " 'scenario': 1}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(train_raw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy.prefer_gpu()\n",
    "\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'tagger', 'ner'])\n",
    "\n",
    "def tokenizer(text):\n",
    "    return [token.text.strip() for token in nlp(text)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split train and valid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of origin training data: 100000\n",
      "# of train data: 80000\n",
      "# of valid data: 20000\n",
      "# of test data: 2000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print('# of origin training data:',len(train_raw))\n",
    "\n",
    "train_raw, valid_raw = train_test_split(train_raw, test_size=0.2, shuffle=False)\n",
    "\n",
    "print('# of train data:',len(train_raw))\n",
    "print('# of valid data:',len(valid_raw))\n",
    "print('# of test data:',len(test_raw))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess for train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data_list, description):\n",
    "    \"\"\"\n",
    "    preprocess from json file to dataframe format\n",
    "    with three columns: dialogue, response, label (only training data)\n",
    "    dialogue are added special token\n",
    "    \n",
    "    \"\"\"\n",
    "    dialogues = []\n",
    "    reponses = []\n",
    "    if description=='train' or description=='valid':\n",
    "        labels = []\n",
    "    \n",
    "    for i,data in enumerate(data_list):\n",
    "        dialogue = []\n",
    "        \n",
    "        # choose previous n turns of utterance to enhance the performance\n",
    "        messages_so_far_list = data['messages-so-far']#[-TURN_LIMIT:]\n",
    "        \n",
    "        for record_dict in messages_so_far_list:\n",
    "            utterance_i = record_dict['utterance']\n",
    "            speaker_i = record_dict['speaker'][-1]\n",
    "            # split utterance into tokens\n",
    "            utterance_i = tokenizer(utterance_i)\n",
    "            dialogue+=utterance_i\n",
    "            dialogue.append('eou')\n",
    "        dialogue.append('sep')\n",
    "        \n",
    "        dialogue = ' '.join(dialogue[-CONTEXT_MAX_LEN:])\n",
    "        \n",
    "        if description=='train' or description=='valid':\n",
    "              \n",
    "            # positive sample\n",
    "            dialogues.append(dialogue)\n",
    "            \n",
    "            correct_response = data['options-for-correct-answers'][0]['utterance']  \n",
    "            correct_response = ' '.join(tokenizer(correct_response)[:RESPONSE_MAX_LEN])\n",
    "            reponses.append(correct_response)\n",
    "        \n",
    "            label = 1\n",
    "            labels.append(label)\n",
    "            \n",
    "\n",
    "            # negative sample\n",
    "            correct_answers = data['options-for-correct-answers'][0]\n",
    "            candidates = data['options-for-next']\n",
    "            if correct_answers in candidates:\n",
    "                candidates.remove(correct_answers)\n",
    "            \n",
    "            # train\n",
    "            if description=='train':\n",
    "                for i in range(4): \n",
    "                    dialogues.append(dialogue)\n",
    "\n",
    "                    #idx = np.random.choice(len(candidates))\n",
    "                    resposne = data['options-for-next'][i]['utterance']\n",
    "                    resposne = ' '.join(tokenizer(resposne)[:RESPONSE_MAX_LEN])\n",
    "                    reponses.append(resposne)\n",
    "\n",
    "                    label = 0\n",
    "                    labels.append(label)\n",
    "            \n",
    "            # valid\n",
    "            else:\n",
    "                for candidate in candidates:\n",
    "                    dialogues.append(dialogue)\n",
    "                    resposne = candidate['utterance']\n",
    "                    resposne = ' '.join(tokenizer(resposne)[:RESPONSE_MAX_LEN])\n",
    "                    reponses.append(resposne)\n",
    "\n",
    "                    label = 0\n",
    "                    labels.append(label)\n",
    "\n",
    "        \n",
    "        else: # test #valid\n",
    "            candidates = data['options-for-next']\n",
    "            for candidate in candidates:\n",
    "                dialogues.append(dialogue)\n",
    "                \n",
    "                response = candidate['utterance']\n",
    "                response = ' '.join(tokenizer(response)[:RESPONSE_MAX_LEN])\n",
    "                reponses.append(response)\n",
    "                \n",
    "                \n",
    "    \n",
    "    if description=='train' or description=='valid':\n",
    "        df = pd.DataFrame(zip(dialogues, reponses, labels), columns=['context','response','label'])\n",
    "        return df\n",
    "    \n",
    "    else:\n",
    "        df = pd.DataFrame(zip(dialogues,reponses), columns=['context','response'])\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(valid_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 10s, sys: 500 ms, total: 3min 10s\n",
      "Wall time: 3min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "trainset = preprocess(train_raw, 'train')\n",
    "validset = preprocess(valid_raw, 'valid')\n",
    "testset = preprocess(test_raw, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I kill precisely ? because it says \" X : no su...</td>\n",
       "      <td>are you still running in root terminal ? if so...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I kill precisely ? because it says \" X : no su...</td>\n",
       "      <td>quite</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I kill precisely ? because it says \" X : no su...</td>\n",
       "      <td>hey join # .  so i can tell you things that th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I kill precisely ? because it says \" X : no su...</td>\n",
       "      <td>did you complete the ubuntu installation ? ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>I kill precisely ? because it says \" X : no su...</td>\n",
       "      <td>how did you run mplayer ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>how do I turn on optical output under gutsy ? ...</td>\n",
       "      <td>oh cool :)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>how do I turn on optical output under gutsy ? ...</td>\n",
       "      <td>does it still run . check top or \" ps aux \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>how do I turn on optical output under gutsy ? ...</td>\n",
       "      <td>then how do you know it does nt work out of th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>how do I turn on optical output under gutsy ? ...</td>\n",
       "      <td>Quanta maybe ? http://quanta.kdewebdev.org/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>how do I turn on optical output under gutsy ? ...</td>\n",
       "      <td>- &gt; are you using any encryption too . ?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  I kill precisely ? because it says \" X : no su...   \n",
       "1  I kill precisely ? because it says \" X : no su...   \n",
       "2  I kill precisely ? because it says \" X : no su...   \n",
       "3  I kill precisely ? because it says \" X : no su...   \n",
       "4  I kill precisely ? because it says \" X : no su...   \n",
       "5  how do I turn on optical output under gutsy ? ...   \n",
       "6  how do I turn on optical output under gutsy ? ...   \n",
       "7  how do I turn on optical output under gutsy ? ...   \n",
       "8  how do I turn on optical output under gutsy ? ...   \n",
       "9  how do I turn on optical output under gutsy ? ...   \n",
       "\n",
       "                                            response  label  \n",
       "0  are you still running in root terminal ? if so...      1  \n",
       "1                                              quite      0  \n",
       "2  hey join # .  so i can tell you things that th...      0  \n",
       "3       did you complete the ubuntu installation ? ?      0  \n",
       "4                          how did you run mplayer ?      0  \n",
       "5                                         oh cool :)      1  \n",
       "6        does it still run . check top or \" ps aux \"      0  \n",
       "7  then how do you know it does nt work out of th...      0  \n",
       "8        Quanta maybe ? http://quanta.kdewebdev.org/      0  \n",
       "9           - > are you using any encryption too . ?      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(trainset))\n",
    "trainset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No help to as why I ca n't install things ? eo...</td>\n",
       "      <td>pgrep -l apt - get</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No help to as why I ca n't install things ? eo...</td>\n",
       "      <td>Kismet is made up by two parts . The server ki...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No help to as why I ca n't install things ? eo...</td>\n",
       "      <td>One sec .  https://help.ubuntu.com/community/W...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No help to as why I ca n't install things ? eo...</td>\n",
       "      <td>ah , xkill</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No help to as why I ca n't install things ? eo...</td>\n",
       "      <td>Thankyou  i 'll have a read of it right now :)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>No help to as why I ca n't install things ? eo...</td>\n",
       "      <td>it 's been many years since I messed with that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>No help to as why I ca n't install things ? eo...</td>\n",
       "      <td>- you can do it a few ways ... set the group o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>No help to as why I ca n't install things ? eo...</td>\n",
       "      <td>gksu gedit /etc / hosts .  comment out ( put a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>No help to as why I ca n't install things ? eo...</td>\n",
       "      <td>time to be reading up on that ' using samba ' ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>hoe do I fix my cd rom it was burning a iso an...</td>\n",
       "      <td>is it a movie ? ubuntu should show an index an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               context  \\\n",
       "0    No help to as why I ca n't install things ? eo...   \n",
       "1    No help to as why I ca n't install things ? eo...   \n",
       "2    No help to as why I ca n't install things ? eo...   \n",
       "3    No help to as why I ca n't install things ? eo...   \n",
       "4    No help to as why I ca n't install things ? eo...   \n",
       "..                                                 ...   \n",
       "96   No help to as why I ca n't install things ? eo...   \n",
       "97   No help to as why I ca n't install things ? eo...   \n",
       "98   No help to as why I ca n't install things ? eo...   \n",
       "99   No help to as why I ca n't install things ? eo...   \n",
       "100  hoe do I fix my cd rom it was burning a iso an...   \n",
       "\n",
       "                                              response  label  \n",
       "0                                   pgrep -l apt - get      1  \n",
       "1    Kismet is made up by two parts . The server ki...      0  \n",
       "2    One sec .  https://help.ubuntu.com/community/W...      0  \n",
       "3                                           ah , xkill      0  \n",
       "4       Thankyou  i 'll have a read of it right now :)      0  \n",
       "..                                                 ...    ...  \n",
       "96   it 's been many years since I messed with that...      0  \n",
       "97   - you can do it a few ways ... set the group o...      0  \n",
       "98   gksu gedit /etc / hosts .  comment out ( put a...      0  \n",
       "99   time to be reading up on that ' using samba ' ...      0  \n",
       "100  is it a movie ? ubuntu should show an index an...      1  \n",
       "\n",
       "[101 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(validset))\n",
    "validset.head(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>I 'm starting to get really pissed off here . ...</td>\n",
       "      <td>apt - get remove whatever .. :) or just edit t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>I 'm starting to get really pissed off here . ...</td>\n",
       "      <td>not all makes are created equally . you might ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>I 'm starting to get really pissed off here . ...</td>\n",
       "      <td>what ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>I 'm starting to get really pissed off here . ...</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>I 'm starting to get really pissed off here . ...</td>\n",
       "      <td>the items I see under the scroll bar there are...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>I 'm starting to get really pissed off here . ...</td>\n",
       "      <td>do you have 2 video cards installed ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>I 'm starting to get really pissed off here . ...</td>\n",
       "      <td>according to apt - cache search , it 's in xmm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>I 'm starting to get really pissed off here . ...</td>\n",
       "      <td>the first one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>I 'm starting to get really pissed off here . ...</td>\n",
       "      <td>some nights it has me in stiches .  that and i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>I 'm starting to get really pissed off here . ...</td>\n",
       "      <td>sweet ai nt it :D</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  I 'm starting to get really pissed off here . ...   \n",
       "1  I 'm starting to get really pissed off here . ...   \n",
       "2  I 'm starting to get really pissed off here . ...   \n",
       "3  I 'm starting to get really pissed off here . ...   \n",
       "4  I 'm starting to get really pissed off here . ...   \n",
       "5  I 'm starting to get really pissed off here . ...   \n",
       "6  I 'm starting to get really pissed off here . ...   \n",
       "7  I 'm starting to get really pissed off here . ...   \n",
       "8  I 'm starting to get really pissed off here . ...   \n",
       "9  I 'm starting to get really pissed off here . ...   \n",
       "\n",
       "                                            response  \n",
       "0  apt - get remove whatever .. :) or just edit t...  \n",
       "1  not all makes are created equally . you might ...  \n",
       "2                                             what ?  \n",
       "3                                                yes  \n",
       "4  the items I see under the scroll bar there are...  \n",
       "5              do you have 2 video cards installed ?  \n",
       "6  according to apt - cache search , it 's in xmm...  \n",
       "7                                      the first one  \n",
       "8  some nights it has me in stiches .  that and i...  \n",
       "9                                  sweet ai nt it :D  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(testset))\n",
    "testset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check CONTEXT_MAX_LEN<=300 & RESPONSE_MAX_LEN <= 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context len: 297\n",
      "response len: 30\n"
     ]
    }
   ],
   "source": [
    "dataset = trainset\n",
    "print('context len:',len(dataset.loc[0,'context'].split()))\n",
    "print('response len:',len(dataset.loc[0,'response'].split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "def splitwords(text):\n",
    "    return text.split()\n",
    "    \n",
    "\n",
    "def collect_words(df, n_workers=4):        \n",
    "    sent_list = []\n",
    "    for i in df.iterrows():\n",
    "        sent_list += i[1]['context'].split('eou')\n",
    "\n",
    "    chunks = [\n",
    "        ' '.join(sent_list[i:i + len(sent_list) // n_workers])\n",
    "        for i in range(0, len(sent_list), len(sent_list) // n_workers)\n",
    "    ]\n",
    "    with Pool(n_workers) as pool:\n",
    "        chunks = pool.map_async(splitwords, chunks)\n",
    "        words = set(sum(chunks.get(), []))\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creat new dictionary\n",
      "CPU times: user 36.4 s, sys: 1.65 s, total: 38.1 s\n",
      "Wall time: 40.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "import pickle\n",
    "\n",
    "if not os.path.exists('saved_files'):\n",
    "    os.mkdir('saved_files')\n",
    "\n",
    "if os.path.isfile('saved_files/dicitonary.pkl') and not BUILD_NEW_DICT:\n",
    "    print('Load existing dictionary')\n",
    "    with open('saved_files/dicitonary.pkl','rb') as f:\n",
    "        words = pickle.load(f)\n",
    "        \n",
    "else:\n",
    "\n",
    "    print('creat new dictionary')\n",
    "    words = set()\n",
    "    words |= collect_words(trainset)\n",
    "    word_dict = {}\n",
    "    for word in words: \n",
    "        word_dict[word]=len(word_dict)\n",
    "\n",
    "    with open('saved_files/dicitonary.pkl','wb') as f:\n",
    "        pickle.dump(word_dict, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## restart run below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding class to save pretrained embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "\n",
    "class Embedding:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        embedding_path (str): Path where embedding are loaded from (text file).\n",
    "        words (None or list): If not None, only load embedding of the words in\n",
    "            the list.\n",
    "        oov_as_unk (bool): If argument `words` are provided, whether or not\n",
    "            treat words in `words` but not in embedding file as `<unk>`. If\n",
    "            true, OOV will be mapped to the index of `<unk>`. Otherwise,\n",
    "            embedding of those OOV will be randomly initialize and their\n",
    "            indices will be after non-OOV.\n",
    "        lower (bool): Whether or not lower the words.\n",
    "        rand_seed (int): Random seed for embedding initialization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, embedding_path,\n",
    "                 words=None, oov_as_unk=True, lower=True, rand_seed=524):\n",
    "        self.word_dict = {}\n",
    "        self.vectors = None\n",
    "        self.lower = lower\n",
    "        self.extend(embedding_path, words, oov_as_unk)\n",
    "        torch.manual_seed(rand_seed)\n",
    "\n",
    "        if '<pad>' not in self.word_dict:\n",
    "            self.add(\n",
    "                '<pad>', torch.zeros(self.get_dim())\n",
    "            )\n",
    "        \n",
    "        if '<bos>' not in self.word_dict:\n",
    "            t_tensor = torch.rand((1, self.get_dim()), dtype=torch.float)\n",
    "            torch.nn.init.orthogonal_(t_tensor)\n",
    "            self.add(\n",
    "                '<bos>', t_tensor\n",
    "            )\n",
    "            \n",
    "        if '<eos>' not in self.word_dict:\n",
    "            t_tensor = torch.rand((1, self.get_dim()), dtype=torch.float)\n",
    "            torch.nn.init.orthogonal_(t_tensor)\n",
    "            self.add(\n",
    "                '<eos>', t_tensor\n",
    "            )\n",
    "        \n",
    "        if '<eou>' not in self.word_dict:\n",
    "            t_tensor = torch.rand((1, self.get_dim()), dtype=torch.float)\n",
    "            torch.nn.init.orthogonal_(t_tensor)\n",
    "            self.add(\n",
    "                '<eou>', t_tensor\n",
    "            )\n",
    "        \n",
    "        if '<sep>' not in self.word_dict:\n",
    "            t_tensor = torch.rand((1, self.get_dim()), dtype=torch.float)\n",
    "            torch.nn.init.orthogonal_(t_tensor)\n",
    "            self.add(\n",
    "                '<sep>', t_tensor\n",
    "            )\n",
    "        \n",
    "        if '<unk>' not in self.word_dict:\n",
    "            self.add('<unk>')\n",
    "\n",
    "    def to_index(self, word):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            word (str)\n",
    "\n",
    "        Return:\n",
    "             index of the word. If the word is not in `words` and not in the\n",
    "             embedding file, then index of `<unk>` will be returned.\n",
    "        \"\"\"\n",
    "        if self.lower:\n",
    "            word = word.lower()\n",
    "\n",
    "        if word not in self.word_dict:\n",
    "            return self.word_dict['<unk>']\n",
    "        else:\n",
    "            return self.word_dict[word]\n",
    "\n",
    "    def get_dim(self):\n",
    "        return self.vectors.shape[1]\n",
    "\n",
    "    def get_vocabulary_size(self):\n",
    "        return self.vectors.shape[0]\n",
    "\n",
    "    def add(self, word, vector=None):\n",
    "        if self.lower:\n",
    "            word = word.lower()\n",
    "\n",
    "        if vector is not None:\n",
    "            vector = vector.view(1, -1)\n",
    "        else:\n",
    "            vector = torch.empty(1, self.get_dim())\n",
    "            torch.nn.init.uniform_(vector)\n",
    "        self.vectors = torch.cat([self.vectors, vector], 0)\n",
    "        self.word_dict[word] = len(self.word_dict)\n",
    "\n",
    "    def extend(self, embedding_path, words, oov_as_unk=True):\n",
    "        self._load_embedding(embedding_path, words)\n",
    "\n",
    "        if words is not None and not oov_as_unk:\n",
    "            # initialize word vector for OOV\n",
    "            for word in words:\n",
    "                if self.lower:\n",
    "                    word = word.lower()\n",
    "\n",
    "                if word not in self.word_dict:\n",
    "                    self.word_dict[word] = len(self.word_dict)\n",
    "\n",
    "            oov_vectors = torch.nn.init.uniform_(\n",
    "                torch.empty(len(self.word_dict) - self.vectors.shape[0],\n",
    "                            self.vectors.shape[1]))\n",
    "\n",
    "            self.vectors = torch.cat([self.vectors, oov_vectors], 0)\n",
    "\n",
    "    def _load_embedding(self, embedding_path, words):\n",
    "        if words is not None:\n",
    "            words = set(words)\n",
    "\n",
    "        vectors = []\n",
    "\n",
    "        with open(embedding_path) as fp:\n",
    "\n",
    "            row1 = fp.readline()\n",
    "            # if the first row is not header\n",
    "            if not re.match('^[0-9]+ [0-9]+$', row1):\n",
    "                # seek to 0\n",
    "                fp.seek(0)\n",
    "            # otherwise ignore the header\n",
    "\n",
    "            for i, line in enumerate(fp):\n",
    "                cols = line.rstrip().split(' ')\n",
    "                word = cols[0]\n",
    "\n",
    "                # skip word not in words if words are provided\n",
    "                if words is not None and word not in words:\n",
    "                    continue\n",
    "                elif word not in self.word_dict:\n",
    "                    self.word_dict[word] = len(self.word_dict)\n",
    "                    vectors.append([float(v) for v in cols[1:]])\n",
    "\n",
    "        vectors = torch.tensor(vectors)\n",
    "        if self.vectors is not None:\n",
    "            self.vectors = torch.cat([self.vectors, vectors], dim=0)\n",
    "        else:\n",
    "            self.vectors = vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new embedding\n",
      "CPU times: user 7.89 s, sys: 205 ms, total: 8.1 s\n",
      "Wall time: 7.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "\n",
    "if os.path.isfile('saved_files/embedding.pkl') and not BUILD_NEW_DICT:\n",
    "    print('Load existing embedding')\n",
    "    with open('saved_files/embedding.pkl','rb') as f:\n",
    "        embedder = pickle.load(f)\n",
    "else:\n",
    "    print('new embedding')\n",
    "\n",
    "    embedder = Embedding('glove.6B.300d.txt', words)\n",
    "    with open('saved_files/embedding.pkl','wb') as f:\n",
    "        pickle.dump(embedder, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26372"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedder.word_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "def label_to_onehot(label):\n",
    "    onehot = [0,0]\n",
    "    onehot[int(label)] = 1\n",
    "    return onehot\n",
    "        \n",
    "def sentence_to_indices(sentence, word_dict):\n",
    "    \"\"\" Convert sentence to its word indices.\n",
    "    Args:\n",
    "        sentence (str): One string.\n",
    "    Return:\n",
    "        indices (list of int): List of word indices.\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    for word in sentence.split():\n",
    "        if word in ['eou','sep']:\n",
    "            word = '<{}>'.format(word)\n",
    "        indices.append(word_dict.to_index(word))\n",
    "    return indices\n",
    "    #return [word_dict.to_index(word) for word in word_tokenize(sentence)]\n",
    "    \n",
    "def get_dataset(dataset, word_dict, n_workers=4):\n",
    "    \"\"\" Load data and return dataset for training and validating.\n",
    "\n",
    "    Args:\n",
    "        data_path (str): Path to the data.\n",
    "    \"\"\"\n",
    "    #dataset = pd.read_csv(data_path, dtype=str)\n",
    "\n",
    "    results = [None] * n_workers\n",
    "    with Pool(processes=n_workers) as pool:\n",
    "        for i in range(n_workers):\n",
    "            batch_start = (len(dataset) // n_workers) * i\n",
    "            if i == n_workers - 1:\n",
    "                batch_end = len(dataset)\n",
    "            else:\n",
    "                batch_end = (len(dataset) // n_workers) * (i + 1)\n",
    "            \n",
    "            batch = dataset[batch_start: batch_end]\n",
    "            results[i] = pool.apply_async(preprocess_samples, args=(batch,word_dict))\n",
    "\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "\n",
    "    processed = []\n",
    "    for result in results:\n",
    "        processed += result.get()\n",
    "    return processed\n",
    "\n",
    "def preprocess_samples(dataset, word_dict):\n",
    "    \"\"\" Worker function.\n",
    "\n",
    "    Args:\n",
    "        dataset (list of dict)\n",
    "    Returns:\n",
    "        list of processed dict.\n",
    "    \"\"\"\n",
    "    processed = []\n",
    "    for sample in tqdm(dataset.iterrows(), total=len(dataset)):\n",
    "        processed.append(preprocess_sample(sample[1], word_dict))\n",
    "\n",
    "    return processed\n",
    "\n",
    "def preprocess_sample(data, word_dict):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data (dict)\n",
    "    Returns:\n",
    "        dict\n",
    "    \"\"\"\n",
    "    processed = {}\n",
    "    processed['context'] = sentence_to_indices(data['context'], word_dict)# for sent in data['context'].split('eou')]\n",
    "    processed['response'] = sentence_to_indices(data['response'], word_dict)\n",
    "    if 'label' in data:\n",
    "        #processed['label'] = label_to_onehot(data['label'])\n",
    "        processed['label'] = int(data['label'])\n",
    "        \n",
    "        \n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Start processing trainset...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[INFO] Start processing validset...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "[INFO] Start processing testset...\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "CPU times: user 32.6 s, sys: 5.81 s, total: 38.4 s\n",
      "Wall time: 2min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if not BUILD_NEW_DICT and os.path.exists('saved_files/train.pkl') and os.path.exists('saved_files/valid.pkl') and os.path.exists('saved_files/test.pkl'):\n",
    "    print('Load existing train, valid, test')\n",
    "    with open('saved_files/train.pkl','rb') as f:\n",
    "        train = pickle.load(f)\n",
    "    with open('saved_files/valid.pkl','rb') as f:\n",
    "        valid = pickle.load(f) \n",
    "    with open('saved_files/test.pkl','rb') as f:\n",
    "        test = pickle.load(f)\n",
    "\n",
    "else:\n",
    "\n",
    "    print('[INFO] Start processing trainset...')\n",
    "    train = get_dataset(trainset, embedder, n_workers=4)\n",
    "    print('[INFO] Start processing validset...')\n",
    "    valid = get_dataset(validset, embedder, n_workers=4)\n",
    "    print('[INFO] Start processing testset...')\n",
    "    test = get_dataset(testset, embedder, n_workers=4)\n",
    "\n",
    "    with open('saved_files/train.pkl','wb') as f:\n",
    "        pickle.dump(train,f)\n",
    "    with open('saved_files/valid.pkl','wb') as f:\n",
    "        pickle.dump(valid,f) \n",
    "    with open('saved_files/test.pkl','wb') as f:\n",
    "        pickle.dump(test,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context len: 297\n",
      "response len: 30\n"
     ]
    }
   ],
   "source": [
    "print('context len:',len(list(train)[0]['context']))\n",
    "print('response len:',len(list(train)[0]['response']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "class dialogueDataset(Dataset):\n",
    "    def __init__(self, data, pad_idx):#, max_len=MAX_SENTENCE_LEN):\n",
    "        self.data = data\n",
    "        self.pad_idx = pad_idx\n",
    "        #self.max_len = max_len\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "        \n",
    "    def collate_fn(self, datas):\n",
    "\n",
    "        max_len_context = max([len(data['context']) for data in datas])\n",
    "        max_len_response = max([len(data['response']) for data in datas])\n",
    "\n",
    "        batch_context = []\n",
    "        batch_response = []\n",
    "        batch_label = []\n",
    "        #sent_len = []\n",
    "        \n",
    "        for data in datas:\n",
    "            #sent_len.append(len(data['context']))\n",
    "            \n",
    "            # dialogue\n",
    "            if len(data['context']) < max_len_context:\n",
    "                data['context'] += [self.pad_idx]*(max_len_context-len(data['context']))\n",
    "            batch_context.append(data['context'])\n",
    "            \n",
    "            # response\n",
    "            if len(data['response']) < max_len_response:\n",
    "                data['response'] += [self.pad_idx]*(max_len_response-len(data['response']))\n",
    "            batch_response.append(data['response'])\n",
    "            \n",
    "            # labels\n",
    "            if 'label' in data:\n",
    "                batch_label.append(data['label'])\n",
    "                \n",
    "        return torch.LongTensor(batch_context), torch.LongTensor(batch_response), torch.FloatTensor(batch_label)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_TOKEN = embedder.word_dict['<pad>']\n",
    "\n",
    "trainData = dialogueDataset(train, PAD_TOKEN)\n",
    "validData = dialogueDataset(valid, PAD_TOKEN)\n",
    "testData = dialogueDataset(test, PAD_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(validData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "i2w = {v:k for k,v in embedder.word_dict.items()} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_i = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"No help to as why I ca n't install things ? eou what package manager were you using ? eou I was using sudo apt - get on Kubuntu . ( I 'd try their irc , but hardly anyone is around . ) eou sep\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validset.loc[data_i,'context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"no help to as why i ca n't install things ? <eou> what package manager were you using ? <eou> i was using sudo apt - get on kubuntu . ( i 'd try their irc , but hardly anyone is around . ) <eou> <sep>\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([i2w[idx] for idx in list(validData)[data_i]['context']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### resposne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kismet is made up by two parts . The server kismet_server and client , kismet_client . Have you configured the server part ?'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validset.loc[data_i,'response']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'kismet is made up by two parts . the server <unk> and client , <unk> . have you configured the server part ?'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([i2w[idx] for idx in list(validData)[data_i]['response']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LocalMatching(c,r):\n",
    "    e_ij = torch.matmul(c,r.transpose(1,2)) # (x timestep) * (r timestep)\n",
    "    alpha_ij = F.softmax(e_ij, dim=2) \n",
    "    beta_ij = F.softmax(e_ij, dim=1)\n",
    "\n",
    "    c_d = torch.matmul(alpha_ij, r)\n",
    "    r_d = torch.matmul(beta_ij.transpose(1,2), c)\n",
    "    \n",
    "    c_l = torch.cat([c, c_d, c - c_d, c * c_d], dim=1) #hidden_size*2 *4\n",
    "    r_l = torch.cat([r, r_d, r - r_d, r * r_d], dim=1)\n",
    "\n",
    "    return c_l, r_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "class crossAtteNet(nn.Module):\n",
    "    def __init__(self, vocabulary_size):\n",
    "        super(crossAtteNet, self).__init__()\n",
    "        self.hidden_dim = 300\n",
    "        self.rnn1 = nn.GRU(vocabulary_size,\n",
    "                                self.hidden_dim,\n",
    "                                bidirectional=True,\n",
    "                                batch_first=True,\n",
    "                                num_layers=2,\n",
    "                                dropout=DROPOUT_RATE)\n",
    "        \n",
    "        self.rnn2 = nn.GRU(self.hidden_dim*2,\n",
    "                                self.hidden_dim,\n",
    "                                bidirectional=True,\n",
    "                                batch_first=True,\n",
    "                                num_layers=2,\n",
    "                                dropout=DROPOUT_RATE)\n",
    "        \n",
    "        self.MLP = nn.Sequential(\n",
    "                        nn.Dropout(DROPOUT_RATE),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(self.hidden_dim*2*4, 256),\n",
    "                        nn.Dropout(DROPOUT_RATE),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(256, 16),\n",
    "                        nn.Dropout(DROPOUT_RATE),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(16, 1),\n",
    "                    )\n",
    "\n",
    "\n",
    "    def forward(self, context, response):\n",
    "        batchsize = context.size(0)\n",
    "        # Input Encoding\n",
    "        context,  _ = self.rnn1(context) # shape: (batchsize, seq_len, hidden_size*2) -->bidirectional\n",
    "        response, _ = self.rnn1(response)\n",
    "        \n",
    "        # Local Matching\n",
    "        c_l, r_l = LocalMatching(context,response) # shape: (batchsize, seq_len*4, hidden_size*2)\n",
    "        \n",
    "        # Matching Composition\n",
    "        context,  _ = self.rnn2(c_l)  # shape: (batchsize, seq_len*4, hidden_size*2)\n",
    "        response, _ = self.rnn2(r_l)\n",
    "        \n",
    "        # Pooling shape: (batchsize, hidden_size*2)\n",
    "        c_max_pool = F.adaptive_max_pool1d(context.permute(0,2,1),1).view(batchsize,-1) \n",
    "        c_avg_pool = F.adaptive_avg_pool1d(context.permute(0,2,1),1).view(batchsize,-1)\n",
    "        \n",
    "        r_max_pool = F.adaptive_max_pool1d(response.permute(0,2,1),1).view(batchsize,-1)\n",
    "        r_avg_pool = F.adaptive_avg_pool1d(response.permute(0,2,1),1).view(batchsize,-1)\n",
    "        \n",
    "        x = torch.cat([c_max_pool, c_avg_pool, r_max_pool, r_avg_pool], dim=1) # shape: (batchsize, hidden_size*2*4)\n",
    "        x = self.MLP(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1():\n",
    "    def __init__(self):\n",
    "        self.threshold = THRESHOLD\n",
    "        self.n_precision = 0\n",
    "        self.n_recall = 0\n",
    "        self.n_corrects = 0\n",
    "        self.name = 'F1'\n",
    "        \n",
    "        self.N = 0\n",
    "        self.correct = 0\n",
    "\n",
    "    def reset(self):\n",
    "        self.n_precision = 0\n",
    "        self.n_recall = 0\n",
    "        self.n_corrects = 0\n",
    "        \n",
    "        self.N = 0\n",
    "        self.correct = 0\n",
    "        \n",
    "    def update(self, predicts, groundTruth, update100=False):\n",
    "        if update100:\n",
    "            self.N += groundTruth\n",
    "            self.correct += predicts\n",
    "            return \n",
    "            \n",
    "        if LOGISTICLOSS:\n",
    "            predicts = torch.sigmoid(predicts)\n",
    "        predicts = predicts > self.threshold\n",
    "        \n",
    "        self.correct += torch.sum(predicts==groundTruth).data.item()\n",
    "        self.N += len(predicts)\n",
    "\n",
    "    def get_score(self):\n",
    "        return self.correct/self.N\n",
    "\n",
    "    def print_score(self):\n",
    "        score = self.get_score()\n",
    "        return '{:.5f}'.format(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def _run_epoch(epoch, embedding, training):\n",
    "    model.train(training)\n",
    "    if training:\n",
    "        description = 'Train'\n",
    "        dataset = trainData\n",
    "        shuffle = True\n",
    "    else:\n",
    "        description = 'Valid'\n",
    "        dataset = validData\n",
    "        shuffle = False\n",
    "        predict_list = []\n",
    "        label_list = []\n",
    "    dataloader = DataLoader(dataset=dataset,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=shuffle,\n",
    "                            collate_fn=dataset.collate_fn,\n",
    "                            num_workers=4)\n",
    "   \n",
    "    \n",
    "    trange = tqdm(enumerate(dataloader), total=len(dataloader), desc=description)\n",
    "    loss = 0\n",
    "    f1_score = F1()\n",
    "    for i, (x, r, y) in trange:\n",
    "        x = embedding(x)\n",
    "        r = embedding(r)\n",
    "        o_labels, batch_loss = _run_iter(x,r,y)\n",
    "        if training:\n",
    "            opt.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        loss += batch_loss.item()\n",
    "        \n",
    "        if training:\n",
    "            f1_score.update(o_labels.cpu(), y)\n",
    "            trange.set_postfix(loss=loss / (i + 1), f1=f1_score.print_score())\n",
    "            \n",
    "        if not training: \n",
    "            predict_list,label_list, f1_score = collect100(predict_list,label_list,o_labels.cpu(), y, f1_score)\n",
    "            if not predict_list and not label_list:\n",
    "                trange.set_postfix(loss=loss / (i + 1), f1=f1_score.print_score())\n",
    "        \n",
    "       \n",
    "    if training:\n",
    "        history['train'].append({'accuracy':f1_score.get_score(), 'loss':loss/ len(trange)})\n",
    "    else:\n",
    "        history['valid'].append({'accuracy':f1_score.get_score(), 'loss':loss/ len(trange)})\n",
    "\n",
    "def _run_iter(x,r,y):\n",
    "    x = x.to(device)\n",
    "    r = r.to(device)\n",
    "    labels = y.to(device)\n",
    "    \n",
    "    o_labels = model(x,r)\n",
    "    o_labels = o_labels.flatten()\n",
    "    l_loss = criteria(o_labels, labels)\n",
    "    return o_labels, l_loss\n",
    "\n",
    "def save(epoch):\n",
    "    if not os.path.exists('model'):\n",
    "        os.makedirs('model')\n",
    "    torch.save(model.state_dict(), 'model/model.pkl.'+str(epoch))\n",
    "    with open('model/history.json', 'w') as f:\n",
    "        json.dump(history, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect100(predict_list, label_list, o_labels, y, f1_score):\n",
    "    predict_list.append(o_labels)\n",
    "    label_list.append(y)\n",
    "    \n",
    "    if len(torch.cat(predict_list))==100 and len(torch.cat(label_list))==100:\n",
    "        pred = torch.cat(predict_list)\n",
    "        label = torch.cat(label_list)\n",
    "        if sum(pred==label).data.item()==100:\n",
    "            predicts = 1\n",
    "        else:\n",
    "            predicts = 0\n",
    "        groundTruth = 1\n",
    "        f1_score.update(predicts, groundTruth, True)\n",
    "        predict_list = []\n",
    "        label_list = []\n",
    "    \n",
    "    return predict_list, label_list, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import trange\n",
    "import json\n",
    "model = crossAtteNet(embedder.get_dim())\n",
    "opt = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "if LOGISTICLOSS:\n",
    "    criteria = torch.nn.BCEWithLogitsLoss()\n",
    "else:\n",
    "    criteria = torch.nn.BCELoss()\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "max_epoch = EPOCH\n",
    "history = {'train':[],'valid':[]}\n",
    "\n",
    "\n",
    "embedding = nn.Embedding(embedder.get_vocabulary_size(),embedder.get_dim())\n",
    "embedding.weight = torch.nn.Parameter(embedder.vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## traaaaaaaaaaaaaain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b073e50859214dcbbaa99b81d50f843f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train', max=20000, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d108f77e6d1a417aa5755ae09236331c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Valid', max=100000, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ab3e981f78240588d5dfaf6ee9aa30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train', max=20000, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b07daf3d555418097d6d373e95456ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Valid', max=100000, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe80c0c8a0e47a7925d9380d06adf82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train', max=20000, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c898a680f3bd492994ce8b3981773f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Valid', max=100000, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2472e4b82f84469aee212356e3a712c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train', max=20000, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b85973665d8b45bcb56765f1d8ea3a3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Valid', max=100000, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab047a088ba49eb8f7e264c4dcd35d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train', max=20000, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4c4b04901a46ef9f0450ac23109589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Valid', max=100000, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4d5c371bb94cdbb5d9df668b2425ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Train', max=20000, style=ProgressStyle(description_width='ini…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "055928c6750b498280bc499800e7c1ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Valid', max=100000, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    print('Epoch: {}'.format(epoch))\n",
    "    _run_epoch(epoch, embedding, True)\n",
    "    _run_epoch(epoch, embedding, False)\n",
    "    save(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy score  [0.0, 19]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "with open('model/history.json', 'r') as f:\n",
    "    history = json.loads(f.read())\n",
    "    \n",
    "train_loss = [l['loss'] for l in history['train']]\n",
    "valid_loss = [l['loss'] for l in history['valid']]\n",
    "train_f1 = [l['accuracy'] for l in history['train']]\n",
    "valid_f1 = [l['accuracy'] for l in history['valid']]\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.title('Loss')\n",
    "plt.plot(train_loss, label='train')\n",
    "plt.plot(valid_loss, label='valid')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.title('Accuracy')\n",
    "plt.plot(train_f1, label='train')\n",
    "plt.plot(valid_f1, label='valid')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print('Best Accuracy score ', max([[l['accuracy'], idx] for idx, l in enumerate(history['valid'])]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66257d5c4b26463f843e94946a3c0c5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Valid', max=100000, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca540c30b5e421cb3b5be4f638ba22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Predict', max=10000, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_id = 13\n",
    "model.load_state_dict(torch.load('model/model.pkl.{}'.format(model_id)))\n",
    "model.train(False)\n",
    "_run_epoch(1, embedding, False)\n",
    "\n",
    "\n",
    "dataloader = DataLoader(dataset=testData,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=False,\n",
    "                            collate_fn=testData.collate_fn,\n",
    "                            num_workers=4)\n",
    "trange = tqdm(enumerate(dataloader), total=len(dataloader), desc='Predict')\n",
    "prediction = []\n",
    "pred_tmp = []\n",
    "for i, (x,r,y) in trange:\n",
    "    x = embedding(x)\n",
    "    r = embedding(r)\n",
    "    o_labels = model(x.to(device),r.to(device))\n",
    "    if LOGISTICLOSS:\n",
    "        o_labels = torch.sigmoid(o_labels)\n",
    "    o_labels_list = list(o_labels.cpu().detach().numpy())\n",
    "    pred_tmp += o_labels_list\n",
    "    if len(pred_tmp)==100:\n",
    "        idx = pred_tmp.index(max(pred_tmp))\n",
    "        prediction.append(idx)\n",
    "        pred_tmp = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = []\n",
    "for pred, test in zip(prediction,test_raw):\n",
    "    example_id = test['example-id']\n",
    "    idx = int(pred)\n",
    "    cand_id = test['options-for-next'][idx]['candidate-id']\n",
    "    predict.append((example_id,cand_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>candidate-id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>80000</td>\n",
       "      <td>UPCSP2NK57BO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>80001</td>\n",
       "      <td>I2Y8EQ62D117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>80002</td>\n",
       "      <td>UPQ8C3AMRFVU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>80003</td>\n",
       "      <td>LFE3AO9FR269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>80004</td>\n",
       "      <td>8EFPBNH9VAVJ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  candidate-id\n",
       "0  80000  UPCSP2NK57BO\n",
       "1  80001  I2Y8EQ62D117\n",
       "2  80002  UPQ8C3AMRFVU\n",
       "3  80003  LFE3AO9FR269\n",
       "4  80004  8EFPBNH9VAVJ"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(predict,columns=['id','candidate-id'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('output'):\n",
    "    os.mkdir('output')\n",
    "df.to_csv('output/output_{}.csv'.format(model_id),index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test model crossAtte  GRU + pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> context shape: torch.Size([2, 4, 5]) \n",
      "\n",
      "tensor([[[-0.0350, -1.1007,  0.3829,  0.3335, -1.0633],\n",
      "         [-1.2499,  0.6995, -1.7510,  0.6592,  1.0666],\n",
      "         [ 1.6129,  0.4030, -1.2573,  2.9812, -2.0950],\n",
      "         [ 0.0533,  2.2751,  0.3682, -0.4741,  0.6466]],\n",
      "\n",
      "        [[-1.0516, -0.6950, -0.3066,  0.4011, -1.1616],\n",
      "         [-0.1179, -0.8043, -0.8432, -1.4834, -0.3640],\n",
      "         [-0.1437,  1.6003, -1.0689, -1.9124,  0.6138],\n",
      "         [-0.7555, -0.6120, -0.8553,  0.1923, -0.0833]]])\n",
      "\n",
      ">>> response shape: torch.Size([2, 3, 5]) \n",
      "\n",
      "tensor([[[ 0.3306, -0.7092,  0.3345,  0.2088,  0.3933],\n",
      "         [-0.3940, -0.5473, -0.9950,  0.0535, -0.6497],\n",
      "         [ 0.6325, -0.5926, -1.2960,  1.1986, -0.7045]],\n",
      "\n",
      "        [[ 0.5703, -0.4356,  1.6268,  0.4945, -1.1229],\n",
      "         [-0.8929,  0.8159, -1.0763, -1.5878,  0.6248],\n",
      "         [-0.3510,  0.0025,  0.1048, -0.3102,  0.0658]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "batchsize = 2\n",
    "embedding_size = 5\n",
    "hidden_size = 2\n",
    "\n",
    "\n",
    "context = torch.randn(batchsize, 4, embedding_size)\n",
    "print('>>> context shape:',context.shape,'\\n')\n",
    "print(context)\n",
    "\n",
    "response = torch.randn(batchsize, 3, embedding_size)\n",
    "print('\\n>>> response shape:',response.shape,'\\n')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. GRU1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context\n",
      ">>> context shape: torch.Size([2, 4, 4]) \n",
      "\n",
      "tensor([[[ 0.1450, -0.0746,  0.4574, -0.1286],\n",
      "         [ 0.2780,  0.1058,  0.6229, -0.0816],\n",
      "         [ 0.3502,  0.3037,  0.6544, -0.1194],\n",
      "         [ 0.4387,  0.3108,  0.4060, -0.0438]],\n",
      "\n",
      "        [[ 0.1909, -0.1364,  0.0875, -0.1420],\n",
      "         [ 0.3035, -0.1253,  0.2364, -0.1037],\n",
      "         [ 0.4093,  0.1498,  0.3700, -0.0592],\n",
      "         [ 0.4845,  0.0880,  0.0744, -0.0701]]], grad_fn=<TransposeBackward1>)\n",
      "\n",
      "response\n",
      ">>> response shape: torch.Size([2, 3, 4]) \n",
      "\n",
      "tensor([[[ 0.1630, -0.0746,  0.3601, -0.1560],\n",
      "         [ 0.2689,  0.0962,  0.4942, -0.1194],\n",
      "         [ 0.3340,  0.0964,  0.2970, -0.1068]],\n",
      "\n",
      "        [[ 0.1630, -0.1476,  0.1028, -0.1105],\n",
      "         [ 0.3169, -0.0079,  0.2468, -0.0668],\n",
      "         [ 0.4058,  0.0111,  0.1124, -0.0612]]], grad_fn=<TransposeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "DROPOUT_RATE = 0.1\n",
    "\n",
    "print('context')\n",
    "rnn1 = nn.GRU(embedding_size,hidden_size,\n",
    "                                bidirectional=True,\n",
    "                                batch_first=True,\n",
    "                                num_layers=2,\n",
    "                                dropout=DROPOUT_RATE)\n",
    "\n",
    "context_output,hidden = rnn1(context)\n",
    "print('>>> context shape:',context_output.shape,'\\n')\n",
    "print(context_output)\n",
    "\n",
    "\n",
    "print('\\nresponse')\n",
    "response_output,hidden = rnn1(response)\n",
    "print('>>> response shape:',response_output.shape,'\\n')\n",
    "print(response_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Local Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context shape: torch.Size([2, 16, 4])\n",
      "response shape: torch.Size([2, 12, 4])\n"
     ]
    }
   ],
   "source": [
    "c_l, r_l = LocalMatching(context_output,response_output)\n",
    "print('context shape:',c_l.shape)\n",
    "print('response shape:',r_l.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. GRU2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context shape after rnn2 : torch.Size([2, 16, 4])\n",
      "response shape after rnn2: torch.Size([2, 12, 4])\n"
     ]
    }
   ],
   "source": [
    "rnn2 = nn.GRU(hidden_size*2,hidden_size,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "            num_layers=2,\n",
    "            )\n",
    "\n",
    "# Matching Composition\n",
    "context,  _ = rnn2(c_l)\n",
    "response, _ = rnn2(r_l)\n",
    "print('context shape after rnn2 :',context.shape)\n",
    "print('response shape after rnn2:',response.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "context_max_pool = F.adaptive_max_pool1d(context.permute(0,2,1),1).view(batchsize,-1)\n",
    "context_avg_pool = F.adaptive_avg_pool1d(response.permute(0,2,1),1).view(batchsize,-1)\n",
    "\n",
    "print(context_max_pool.shape)\n",
    "print(context_avg_pool.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4])\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "response_max_pool = F.adaptive_max_pool1d(r_l.permute(0,2,1),1).view(batchsize,-1)\n",
    "response_avg_pool = F.adaptive_avg_pool1d(r_l.permute(0,2,1),1).view(batchsize,-1)\n",
    "\n",
    "print(response_max_pool.shape)\n",
    "print(response_avg_pool.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 16])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.cat([context_max_pool, context_avg_pool, response_max_pool, response_avg_pool], dim=1)\n",
    "x.shape"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of GRU_GCN_pack.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}